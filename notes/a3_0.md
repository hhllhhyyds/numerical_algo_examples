# 解线性方程组

## 高斯消元

复杂度 $O(n^3)$

## LU 分解

## PA = LU 分解

若主元很小，则需要乘大数才能消去，导致相对小的数被忽略，带来误差。因此通过把绝对值最大的主元置换来解决该问题。

## 矩阵条件数

设 $Ax=b$ 近似解为 $x_a$, 有 $A(x - x_a) = r$,

$$||x-x_a||\le ||A^{-1}|| \cdot ||r||$$
$$||b||\le ||A|| \cdot ||x||$$

$$\frac{||x-x_a||}{||x||}/\frac{||r||}{||b||}\le ||A||||A^{-1}|| = cond(A)$$

## 迭代方法

* 严格主对角矩阵
    $|a_{ii}| > \sum_{i \ne j}|a_{ij}|$

* 雅可比方法
    $$Ax=b = (D+L+U)x$$
    
    $$x_{k+1} = D^{-1}(b - (L+U)x_k)$$

* 高斯-塞德尔方法
    $$(L+D)x_{k+1} = b - U x_k$$
    $$x_{k+1} = D^{-1}(b - U x_k - L x_{k+1})$$

### 收敛性

对雅可比方法和高斯-塞德尔方法，严格主对角矩阵是收敛的充分不必要条件

### 迭代方法相比高斯消元的优势

单次迭代的复杂度为 $O(n^2)$

* 若初始值在解的附近，则只需少次迭代即可
* 若为稀疏矩阵，矩阵中的有效元素个数为 $(O(n))$, 则单次迭代的复杂度为 $O(n)$

在上述两种情况下，迭代方法都优于直接解法。对稀疏矩阵使用直接解法反而会把矩阵填满，占用更大的内存。

## 对称正定矩阵

对称正定矩阵等价于该矩阵的所有特征值为正数

### cholesky 分解

对称正定矩阵分解为上三角矩阵，复杂度 $O(n^3)$, 类似于 LU 分解。对称正定矩阵的 cholesky 分解必定存在，若 cholesky 分解过程中发现主元小于等于 0，则该矩阵不是对称正定矩阵。

这意味着对称正定矩阵一定是有解的。

**问题**：判断一个矩阵是否是对称正定矩阵，最快的办法是什么？
初步判断这应该也是一个 $O(n^3)$ 复杂度的问题

### 共轭梯度法

共轭梯度法打开了使用迭代法求解稀疏矩阵的新纪元

* 思路
    考虑正交性，每次迭代消除误差的一个垂直分量

* A 内积
    设 $A$ 为 $n\times n$ 对称正定矩阵，定义 $A$ 内积
    $$(v, w)_A = v^T A w$$

    $A$ 内积具有
    * 对称性 $(v,w)_A = (w, v)_A$
    * 线性性
    * 正定性

* 算法
    $x_0$ = initial guess\
    $d_0 = r_0 = b - A x_0$\
    **for** $k = 0,1,2,...,n-1$\
    $\quad$ **if** $r_k = 0$, **stop, end**\
    $\quad$ $\alpha_k = \frac{r_k^T r_k}{d_k^T A d_k}$\
    $\quad$ $x_{k+1} = x_k + \alpha_k d_k$\
    $\quad$ $r_{k+1} = b - Ax_{k+1} = r_k - \alpha_k A d_k$\
    $\quad$ $\beta_k = \frac{r_{k+1}^T r_{k+1}}{r_k^T r_k}$\
    $\quad$ $d_{k+1} = r_{k+1} + \beta_k d_k$\
    **end** 

* 劣势: 对非稀疏矩阵复杂度是高斯消元的 3 倍
* 优势: 
    1. 算法简单
    2. 对于对称正定矩阵，迭代 n 次必然有解
    3. 满足误差需求即可停止迭代
    4. 若初始值在解附近则少次迭代即可
    5. 对稀疏矩阵优势巨大，可在 $O(kn)$ 复杂度下完成，其中 $k$ 为迭代次数

### precodition

共轭梯度法存在一个陷阱，对条件数大的矩阵，
1. 很快积累舍入误差
2. 收敛速度很慢

因此需要 precodition 技术来修正这个问题，把求解 $Ax=b$ 的问题转变为求解 $M^{-1}Ax=M^{-1}b$ 问题。其中 $M$ 是一个可逆矩阵，称为 preconditioner。

$M$ 的选取标准是
1. $M$ 的逆容易求得
2. $M^{-1}A$ 的条件数小

* 算法
    $x_0$ = initial guess\
    $r_0 = b - A x_0$\
    $d_0 = z_0 = M^{-1} r_0$\
    **for** $k = 0,1,2,...,n-1$\
    $\quad$ **if** $r_k = 0$, **stop, end**\
    $\quad$ $\alpha_k = \frac{r_k^T z_k}{d_k^T A d_k}$\
    $\quad$ $x_{k+1} = x_k + \alpha_k d_k$\
    $\quad$ $r_{k+1} =  r_k - \alpha_k A d_k$\
    $\quad$ $z_{k+1} = M^{-1}r_{k+1}$\
    $\quad$ $\beta_k = \frac{r_{k+1}^T z_{k+1}}{r_k^T z_k}$\
    $\quad$ $d_{k+1} = z_{k+1} + \beta_k d_k$\
    **end** 

* Jacobi preconditioner

    M 取为 A 的对角线元素组成的矩阵

* symmetric successive over-relaxation (SSOR) preconditioner

    $A = L + D + U$\
    $M = (D + \omega L)D^{-1}(D + \omega U)$

    $\omega \in (0,2).\ \omega = 1$ 即为 Gauss–Seidel preconditioner